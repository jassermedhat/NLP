{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "facd0eb7",
   "metadata": {},
   "source": [
    "üìò Step 1: Text Extraction and Structuring Pipeline\n",
    "This notebook defines a pipeline that:\n",
    "\n",
    "1. Extracts raw text from .txt, .docx, or .pdf files.\n",
    "\n",
    "2. Cleans the raw text to remove formatting noise.\n",
    "\n",
    "3. Identifies headers and segments the content into structured sections.\n",
    "\n",
    "4. Outputs the result as a JSON file and previews the first few sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82837afb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50af1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import fitz  # PyMuPDF\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc014d",
   "metadata": {},
   "source": [
    "### üìÑ Text Extraction Functions for Different File Types\n",
    "\n",
    "This section defines utility functions to extract raw text content from `.txt`, `.docx`, and `.pdf` files. These functions handle different formats and ensure the text is cleaned and returned as a unified string.\n",
    "\n",
    "- **`extract_text_from_txt(path)`**  \n",
    "  Opens a plain text file and reads its contents using UTF-8 encoding.\n",
    "\n",
    "- **`extract_text_from_docx(path)`**  \n",
    "  Uses `python-docx` to read paragraph texts from a Word document (.docx), removing empty lines.\n",
    "\n",
    "- **`extract_text_from_pdf(path)`**  \n",
    "  Uses `PyMuPDF` (imported as `fitz`) to extract text from each page of a PDF document. If reading fails, a warning is printed.\n",
    "\n",
    "- **`load_text(file_path)`**  \n",
    "  Detects the file type based on extension and calls the corresponding extraction function. Raises an error if the file format is unsupported.\n",
    "\n",
    "\n",
    "These functions are essential for preprocessing text data from various file formats in the MCQ generation pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c790bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_txt(path):\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        return file.read()\n",
    "\n",
    "def extract_text_from_docx(path):\n",
    "    doc = Document(path)\n",
    "    return '\\n'.join(para.text.strip() for para in doc.paragraphs if para.text.strip())\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    text = ''\n",
    "    try:\n",
    "        with fitz.open(path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to read PDF '{path}': {e}\")\n",
    "    return text\n",
    "\n",
    "def load_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    loaders = {'.pdf': extract_text_from_pdf, '.docx': extract_text_from_docx, '.txt': extract_text_from_txt}\n",
    "    if ext not in loaders:\n",
    "        raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "    return loaders[ext](file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728ec71",
   "metadata": {},
   "source": [
    "### üßπ Text Cleaning and Structuring Functions\n",
    "\n",
    "This section provides utilities to clean raw extracted text and organize it into meaningful sections for downstream processing (e.g., question generation).\n",
    "\n",
    "---\n",
    "\n",
    "#### **`clean_raw_text(raw_text)`**\n",
    "Performs basic cleaning on raw text:\n",
    "- Removes page numbers and common bullet symbols.\n",
    "- Normalizes spacing and newlines.\n",
    "- Filters out OCR artifacts and control characters.\n",
    "- Strips leading/trailing whitespace from each line.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`is_probable_header(line)`**\n",
    "Heuristic to detect section headers:\n",
    "- Excludes list items (e.g., `1)`, `a)`).\n",
    "- Detects lines ending in `:` or `-`.\n",
    "- Detects mostly capitalized short lines or fully uppercase headings.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`structure_text_to_sections(text)`**\n",
    "Splits the text into sections based on probable headers and paragraph structure:\n",
    "- Groups lines under detected headers.\n",
    "- If no header is detected before content, assigns a default `\"Document\"` header.\n",
    "- Ignores empty lines and formats content as paragraphs.\n",
    "\n",
    "Returns a list of sections, each with:\n",
    "```json\n",
    "{\n",
    "  \"header\": \"Section Title\",\n",
    "  \"content\": \"Associated paragraph text\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8647421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_raw_text(raw_text):\n",
    "    # Basic cleaning: remove page numbers, bullets, weird characters, multiple spaces, multiple newlines\n",
    "    text = re.sub(r'\\n\\d+\\n', '\\n', raw_text)  # Remove isolated page numbers\n",
    "    text = re.sub(r'[‚Ä¢ÔÉò‚óè‚ñ™‚ñ†\\u2022\\uf0b7]', '', text)  # Remove common bullets\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)  # Replace multiple spaces/tabs with single space\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)  # Limit newlines to max two\n",
    "\n",
    "    # Remove obvious OCR garbage or corrupted words (customize as needed)\n",
    "    text = re.sub(r'\\bCo\\s*i\\s*ant\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]+', '', text)  # Remove control chars\n",
    "\n",
    "    # Strip trailing/leading spaces on each line\n",
    "    lines = [line.strip() for line in text.splitlines()]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def is_probable_header(line):\n",
    "    line = line.strip()\n",
    "    # Exclude numbered or lettered list items like '1) ...', 'a) ...', '2. ...'\n",
    "    if re.match(r'^(\\d+[\\.\\)]|[a-zA-Z][\\.\\)])\\s', line):\n",
    "        return False\n",
    "\n",
    "    # Ends with colon or dash\n",
    "    if re.search(r'[:\\-]\\s*$', line):\n",
    "        return True\n",
    "\n",
    "    # Mostly capitalized words, short line\n",
    "    tokens = line.split()\n",
    "    if 1 <= len(tokens) <= 15:\n",
    "        upper_words = sum(1 for t in tokens if t and t[0].isupper())\n",
    "        if upper_words / len(tokens) > 0.7:\n",
    "            return True\n",
    "\n",
    "    # Fully uppercase (ignore short lines)\n",
    "    if len(line) > 3 and line.isupper():\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def structure_text_to_sections(text):\n",
    "    lines = text.splitlines()\n",
    "    sections = []\n",
    "    current_header = None\n",
    "    current_content = []\n",
    "\n",
    "    for idx, line in enumerate(lines):\n",
    "        if not line.strip():\n",
    "            # Empty line, consider as paragraph break - add current content if any\n",
    "            if current_content:\n",
    "                # Append paragraph (join with space)\n",
    "                current_content.append('')  # Add paragraph break as empty string\n",
    "            continue\n",
    "\n",
    "        if is_probable_header(line):\n",
    "            # Save previous section if exists\n",
    "            if current_header or current_content:\n",
    "                content_text = \" \".join(p for p in current_content if p).strip()\n",
    "                if current_header is None:\n",
    "                    # No header before content? Use default header\n",
    "                    current_header = \"Document\"\n",
    "                sections.append({\n",
    "                    \"header\": current_header,\n",
    "                    \"content\": content_text\n",
    "                })\n",
    "                current_content = []\n",
    "            current_header = line.rstrip(':-').strip()\n",
    "        else:\n",
    "            current_content.append(line.strip())\n",
    "\n",
    "    # Add last section\n",
    "    if current_header or current_content:\n",
    "        content_text = \" \".join(p for p in current_content if p).strip()\n",
    "        if current_header is None:\n",
    "            current_header = \"Document\"\n",
    "        sections.append({\n",
    "            \"header\": current_header,\n",
    "            \"content\": content_text\n",
    "        })\n",
    "\n",
    "    # Remove empty content sections if any\n",
    "    sections = [s for s in sections if s['content'].strip() != '']\n",
    "\n",
    "    return sections\n",
    "\n",
    "def save_json(data, path):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242fe90",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Document Preprocessing Pipeline\n",
    "\n",
    "#### **`preprcess(filepath)`**\n",
    "\n",
    "This is the main orchestration function for processing input files and transforming them into structured section-based JSON.\n",
    "\n",
    "**Steps performed:**\n",
    "1. **Validation**: Checks if the file exists; raises an error if not.\n",
    "2. **Extraction**: Loads text using `load_text()` depending on the file type (.txt, .docx, .pdf).\n",
    "3. **Cleaning**: Cleans the raw text using `clean_raw_text()` to remove noise, bullets, OCR artifacts, and normalize spacing.\n",
    "4. **Structuring**: Organizes the cleaned text into logical sections using `structure_text_to_sections()`.\n",
    "5. **Saving**: Outputs the final structured data into `structured_output.json`.\n",
    "6. **Preview**: Prints the first 3 sections of the structured result for verification.\n",
    "\n",
    "**Output Example:**\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"header\": \"Introduction\",\n",
    "    \"content\": \"This section provides an overview of the topic...\"\n",
    "  },\n",
    "  ...\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92dc620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprcess(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"File '{filepath}' does not exist.\")\n",
    "\n",
    "    print(f\"Processing file: {filepath}\")\n",
    "\n",
    "    raw_text = load_text(filepath)\n",
    "    cleaned_text = clean_raw_text(raw_text)\n",
    "    sections = structure_text_to_sections(cleaned_text)\n",
    "\n",
    "    if not sections:\n",
    "        print(\"‚ö†Ô∏è Warning: No sections found after processing.\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Found {len(sections)} sections.\")\n",
    "\n",
    "    # Save to JSON\n",
    "    save_json(sections, \"structured_output.json\")\n",
    "    print(\"Structured JSON saved to 'structured_output.json'\")\n",
    "\n",
    "    # Print first 3 sections as preview\n",
    "    print(\"\\n--- Sample output (first 3 sections) ---\\n\")\n",
    "    print(json.dumps(sections[:3], ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b83aa",
   "metadata": {},
   "source": [
    "üìò **Step 2: Sentence-Level Content Enrichment and Relevance Scoring**\n",
    "\n",
    "This notebook defines a pipeline that:\n",
    "\n",
    "1. **Loads** structured JSON output from Step 1.\n",
    "\n",
    "2. **Segments** each section‚Äôs content into individual sentences using spaCy.\n",
    "\n",
    "3. **Cleans** each sentence by removing numbering, bullet points, and extra whitespace.\n",
    "\n",
    "4. **Extracts**:\n",
    "   - **Keywords** using KeyBERT (up to 5 per sentence).\n",
    "   - **Named Entities** using a BERT-based NER model.\n",
    "\n",
    "5. **Computes Relevance** of each sentence against the global document context using SentenceTransformer embeddings and cosine similarity.\n",
    "\n",
    "6. **Combines** all results into a structured format with:\n",
    "   - Sentence metadata\n",
    "   - Extracted keywords and entities\n",
    "   - Relevance scores\n",
    "   - Answer candidate list\n",
    "\n",
    "7. **Filters** sentences by a relevance score threshold (‚â• 0.5).\n",
    "\n",
    "8. **Saves** the processed output to `processed_stage2.json` for use in MCQ generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d7d0b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a76bf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jasse\\anaconda3\\envs\\final_pro\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import spacy\n",
    "from keybert import KeyBERT\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc5eb1",
   "metadata": {},
   "source": [
    "### ü§ñ Load NLP Models (One-Time Setup)\n",
    "\n",
    "This cell initializes and loads all required models used for Stage 2 of the MCQ generation pipeline: keyword extraction, NER, and sentence relevance scoring.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Model Initializations:**\n",
    "\n",
    "- **spaCy (`en_core_web_sm`)**  \n",
    "  For general-purpose NLP tasks such as tokenization, POS tagging, and sentence segmentation.\n",
    "\n",
    "- **KeyBERT (`KeyBERT()`)**  \n",
    "  Used for unsupervised keyword/keyphrase extraction based on document embeddings.\n",
    "\n",
    "- **SentenceTransformer (`all-MiniLM-L6-v2`)**  \n",
    "  Efficient sentence embedding model used for measuring similarity and relevance between sentences and keywords.\n",
    "\n",
    "- **Hugging Face NER Pipeline (`dslim/bert-base-NER`)**  \n",
    "  Transformer-based Named Entity Recognition pipeline that identifies entities (e.g., person, organization, location) and aggregates overlapping spans.\n",
    "\n",
    "These models are loaded once and reused throughout the pipeline to optimize performance and reduce initialization time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6a39b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load models once\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "kw_model = KeyBERT()\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=\"dslim/bert-base-NER\",\n",
    "    tokenizer=\"dslim/bert-base-NER\",\n",
    "    aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547941e5",
   "metadata": {},
   "source": [
    "### ‚úÇÔ∏è Sentence-Level Processing Functions\n",
    "\n",
    "These functions operate on individual sentences to clean, segment, extract keywords/entities, and compute relevance scores. They form the core of Stage 2 in the MCQ generation pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`clean_sentence(sentence)`**\n",
    "- Removes leading bullets, numbers, or formatting characters.\n",
    "- Replaces newline characters with spaces.\n",
    "- Returns a clean, normalized sentence string.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`segment_sentences(text)`**\n",
    "- Uses `spaCy` to split the cleaned text into sentences.\n",
    "- Filters out very short sentences (< 15 characters) to retain only meaningful content.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`extract_keywords(sentence, top_n=5)`**\n",
    "- Uses `KeyBERT` to extract up to `top_n` keywords or keyphrases (1-3 grams).\n",
    "- Stop words are excluded using the `'english'` list.\n",
    "- Returns a list of top-ranked keywords.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`extract_entities(sentence)`**\n",
    "- Uses the Hugging Face `dslim/bert-base-NER` pipeline to extract named entities from the sentence.\n",
    "- Removes duplicate and whitespace-only entities.\n",
    "- Returns a list of unique entity mentions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`compute_relevance(sentence, context_emb)`**\n",
    "- Encodes the sentence using `SentenceTransformer` (`all-MiniLM-L6-v2`).\n",
    "- Computes cosine similarity with a precomputed context embedding.\n",
    "- Returns a rounded relevance score (e.g., `0.8437`).\n",
    "\n",
    "---\n",
    "\n",
    "> üß† These functions are essential for understanding sentence significance, extracting key concepts, and preparing data for high-quality question generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8619dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    # Remove leading numbering or bullets in sentences and newlines inside\n",
    "    sentence = re.sub(r'^[\\d\\)\\.\\-\\s]+', '', sentence)\n",
    "    sentence = sentence.replace('\\n', ' ').strip()\n",
    "    return sentence\n",
    "\n",
    "def segment_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if len(sent.text.strip()) > 15]\n",
    "\n",
    "def extract_keywords(sentence, top_n=5):\n",
    "    kws = kw_model.extract_keywords(sentence, keyphrase_ngram_range=(1, 3), stop_words='english', top_n=top_n)\n",
    "    return [kw[0] for kw in kws]\n",
    "\n",
    "def extract_entities(sentence):\n",
    "    entities = ner_pipeline(sentence)\n",
    "    # Aggregate unique entity texts, filter punctuation and spaces\n",
    "    unique_entities = list({ent['word'].strip() for ent in entities if ent['word'].strip() and not ent['word'].isspace()})\n",
    "    return unique_entities\n",
    "\n",
    "def compute_relevance(sentence, context_emb):\n",
    "    sent_emb = sentence_model.encode(sentence, convert_to_tensor=True)\n",
    "    score = util.pytorch_cos_sim(sent_emb, context_emb).item()\n",
    "    return round(score, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32754c",
   "metadata": {},
   "source": [
    "### üß† Section-Level Processing & Global Context\n",
    "\n",
    "These functions are responsible for analyzing each structured section from the document. They generate per-sentence metadata including relevance scores, keywords, and entities, which are crucial for targeted question generation.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`process_section(section, global_context_emb)`**\n",
    "Processes a single structured section (`{\"header\", \"content\"}`):\n",
    "- Segments the section content into sentences.\n",
    "- Cleans each sentence and extracts:\n",
    "  - **Keywords** using `KeyBERT`\n",
    "  - **Named Entities** using a transformer-based NER model\n",
    "  - **Answer Candidates** from entities or fallback keywords\n",
    "  - **Relevance Score** based on cosine similarity with a global context embedding\n",
    "- Returns a list of enriched sentence records like:\n",
    "```json\n",
    "{\n",
    "  \"header\": \"Introduction\",\n",
    "  \"sentence_num\": 1,\n",
    "  \"sentence\": \"Machine learning is a subset of AI.\",\n",
    "  \"clean_sentence\": \"Machine learning is a subset of AI.\",\n",
    "  \"keywords\": [\"machine learning\", \"AI\"],\n",
    "  \"entities\": [\"AI\"],\n",
    "  \"answer_candidates\": [\"AI\"],\n",
    "  \"relevance_score\": 0.8731\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2f5c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_section(section, global_context_emb):\n",
    "    \"\"\"\n",
    "    Process a single section {header, content}:\n",
    "    - Segment content to sentences\n",
    "    - For each sentence, extract keywords, entities, compute relevance vs global context\n",
    "    \"\"\"\n",
    "    header = section.get('header', '').strip()\n",
    "    content = section.get('content', '').strip()\n",
    "    combined_text = f\"{header}. {content}\"  # Use header+content as local context if needed\n",
    "    \n",
    "    # Compute local context embedding for relevance comparison (optional: could use global context too)\n",
    "    local_context_emb = sentence_model.encode(combined_text, convert_to_tensor=True)\n",
    "    \n",
    "    sentences = segment_sentences(content)\n",
    "    results = []\n",
    "    for i, sent in enumerate(sentences):\n",
    "        clean_sent = clean_sentence(sent)\n",
    "        keywords = extract_keywords(clean_sent)\n",
    "        entities = extract_entities(clean_sent)\n",
    "        answer_candidates = entities if entities else keywords\n",
    "        relevance_score = compute_relevance(clean_sent, global_context_emb)\n",
    "        \n",
    "        results.append({\n",
    "            \"header\": header,\n",
    "            \"sentence_num\": i + 1,\n",
    "            \"sentence\": sent,\n",
    "            \"clean_sentence\": clean_sent,\n",
    "            \"keywords\": keywords,\n",
    "            \"entities\": entities,\n",
    "            \"answer_candidates\": answer_candidates,\n",
    "            \"relevance_score\": relevance_score\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def load_structured_json(path=\"structured_output.json\"):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def build_global_context(sections, max_chars=2048):\n",
    "    # Combine headers + contents to build a global context string for relevance\n",
    "    combined_text = \" \".join(f\"{sec.get('header','')} {sec.get('content','')}\" for sec in sections)\n",
    "    return combined_text[:max_chars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545e3ea",
   "metadata": {},
   "source": [
    "### üì§ Stage 2: Content Extraction Pipeline (`extractions()`)\n",
    "\n",
    "This function runs the full **Stage 2** processing flow of the MCQ generation pipeline. It enriches structured document sections by extracting semantic metadata per sentence.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Steps Performed:**\n",
    "\n",
    "1. **Load Structured Data**\n",
    "   - Reads `structured_output.json` generated from Stage 1.\n",
    "\n",
    "2. **Build Global Context**\n",
    "   - Constructs a truncated global context string for semantic relevance comparison.\n",
    "   - Embeds the global context using `SentenceTransformer`.\n",
    "\n",
    "3. **Process Each Section**\n",
    "   - For each section, it:\n",
    "     - Segments content into sentences.\n",
    "     - Cleans, extracts keywords and named entities.\n",
    "     - Computes cosine similarity to global context (relevance).\n",
    "     - Collects enriched metadata per sentence.\n",
    "\n",
    "4. **Filter by Relevance**\n",
    "   - Filters results to only keep sentences with a relevance score ‚â• `0.5`.\n",
    "\n",
    "5. **Save Results**\n",
    "   - Writes enriched and filtered sentence metadata to `processed_stage2.json`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Output:**\n",
    "- ‚úÖ Raw processed sentences: `len(all_results)`\n",
    "- üîç Filtered sentences by relevance ‚â• `0.5`: `len(filtered_results)`\n",
    "- üíæ Output file: `processed_stage2.json`\n",
    "\n",
    "---\n",
    "\n",
    "> üß© This output serves as the foundation for **Stage 3** ‚Äì Multiple Choice Question (MCQ) generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832652fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractions():\n",
    "    structured_data = load_structured_json(\"structured_output.json\")\n",
    "    global_context_text = build_global_context(structured_data)\n",
    "    global_context_emb = sentence_model.encode(global_context_text, convert_to_tensor=True)\n",
    "\n",
    "    all_results = []\n",
    "    for section in structured_data:\n",
    "        section_results = process_section(section, global_context_emb)\n",
    "        all_results.extend(section_results)\n",
    "\n",
    "    # Optionally filter by relevance threshold (e.g., 0.5)\n",
    "    filtered_results = [r for r in all_results if r[\"relevance_score\"] >= 0.5]\n",
    "\n",
    "    # Save output for MCQ generation\n",
    "    with open(\"processed_stage2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(filtered_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Processed {len(all_results)} sentences, filtered to {len(filtered_results)} by relevance >= 0.5\")\n",
    "    print(\"Output saved to 'processed_stage2.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e48fa7c",
   "metadata": {},
   "source": [
    "üìò **Step 3: MCQ Generation from Enriched Sentences**\n",
    "\n",
    "This notebook defines a pipeline that:\n",
    "\n",
    "1. **Loads** processed sentence-level data from `processed_stage2.json`.\n",
    "\n",
    "2. **Selects** key answer candidates (entities or keywords) from each sentence.\n",
    "\n",
    "3. **Generates Questions** using the `valhalla/t5-small-qg-hl` model by highlighting the answer in the sentence.\n",
    "\n",
    "4. **Handles Abbreviations**:\n",
    "   - Detects acronyms related to answers in parentheses.\n",
    "   - Replaces abbreviations in the generated question with the full answer for clarity.\n",
    "\n",
    "5. **Cleans Questions** to:\n",
    "   - Ensure minimum length and readability.\n",
    "   - Prevent the answer from appearing directly in the question.\n",
    "\n",
    "6. **Generates Distractors** using:\n",
    "   - **Embedding-based similarity** with `SentenceTransformer`.\n",
    "   - **WordNet** as a fallback for semantic distractors.\n",
    "\n",
    "7. **Shuffles and Formats** questions with 1 correct answer + 3 distractors as options.\n",
    "\n",
    "8. **Filters** out low-quality or incomplete MCQs.\n",
    "\n",
    "9. **Saves** the final set of MCQs to `improved_mcqs.json` for use in educational applications.\n",
    "\n",
    "‚úÖ The script ensures each MCQ is contextually grounded, diverse, and avoids answer leakage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220d326",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19e510a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from typing import List\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from nltk.corpus import wordnet\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83561920",
   "metadata": {},
   "source": [
    "This cell prepares the environment and loads models required for generating Multiple Choice Questions (MCQs) from the processed content.\n",
    "\n",
    "---\n",
    "\n",
    "#### üì• 1. Download NLTK WordNet Resources\n",
    "These are required for generating high-quality distractors using synonyms and semantic relationships.\n",
    "\n",
    "---\n",
    "\n",
    "#### ü§ñ 2. Load Question Generation Model\n",
    "- **Model:** `valhalla/t5-small-qg-hl`  \n",
    "- **Task:** `text2text-generation`  \n",
    "- Used to generate **cloze-style questions** by highlighting the answer in the sentence context.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† 3. Load Sentence Embedding Model for Distractor Similarity\n",
    "- **Model:** `all-MiniLM-L6-v2` via `SentenceTransformer`  \n",
    "- Used to **rank and filter distractor options** based on semantic similarity to the correct answer.\n",
    "\n",
    "---\n",
    "\n",
    "Each record includes:\n",
    "- ‚úÖ Clean sentence  \n",
    "- üß© Answer candidates (entities or keywords)  \n",
    "- üìä Relevance score  \n",
    "- üè∑Ô∏è Keywords and entities\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff4d9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jasse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jasse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Ensure nltk data is downloaded\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "# Load the QG model with proper task\n",
    "qg_pipeline = pipeline(\"text2text-generation\", model=\"valhalla/t5-small-qg-hl\")\n",
    "\n",
    "# Load embedding model for distractors\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd062927",
   "metadata": {},
   "source": [
    "This section defines the core logic used in **Stage 3** of the pipeline: generating cloze-style multiple-choice questions (MCQs) using a pre-trained question generation model and creating distractors with lexical and semantic techniques.\n",
    "\n",
    "---\n",
    "\n",
    "#### `generate_question_qg(context, answer)`\n",
    "- Uses `valhalla/t5-small-qg-hl` (T5-based model) to generate a question.\n",
    "- Replaces the `answer` in the `context` with `<hl>` tags.\n",
    "- Returns the generated question text or an empty string if:\n",
    "  - The answer is not in context.\n",
    "  - An error occurs during generation.\n",
    "\n",
    "---\n",
    "\n",
    "#### `get_wordnet_distractors(word)`\n",
    "- Uses **WordNet** (NLTK) to retrieve lexical distractors:\n",
    "  - Extracts alternative lemmas from synsets.\n",
    "  - Cleans and filters out duplicates or exact matches.\n",
    "  - Returns up to 5 distractor candidates.\n",
    "\n",
    "---\n",
    "\n",
    "#### `get_embedding_distractors(correct_answer, context, top_k=5)`\n",
    "- Uses **sentence embeddings** for semantic distractor generation:\n",
    "  - Extracts candidate words from context (filtered for length, punctuation, and duplication).\n",
    "  - Computes cosine similarity between the correct answer and candidate words.\n",
    "  - Sorts by similarity and returns the top `k` most relevant distractors.\n",
    "\n",
    "---\n",
    "\n",
    "> ‚úÖ This hybrid method ensures that generated MCQs are not only contextually relevant but also pedagogically useful with diverse distractors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "febb7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_qg(context: str, answer: str) -> str:\n",
    "    \"\"\"Generate a question using valhalla/t5-small-qg-hl with <hl> highlighting.\"\"\"\n",
    "    if answer not in context:\n",
    "        return \"\"  # Avoid incorrect highlighting\n",
    "    highlighted = context.replace(answer, f\"<hl> {answer} <hl>\")\n",
    "    prompt = f\"generate question: {highlighted}\"\n",
    "    try:\n",
    "        result = qg_pipeline(prompt, max_length=64, do_sample=False)\n",
    "        return result[0][\"generated_text\"].strip() if result else \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"QG error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def get_wordnet_distractors(word: str) -> List[str]:\n",
    "    \"\"\"Generate distractors using WordNet.\"\"\"\n",
    "    distractors = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            name = lemma.name().replace(\"_\", \" \").lower()\n",
    "            if name != word.lower():\n",
    "                distractors.add(name)\n",
    "    return list(distractors)[:5]\n",
    "\n",
    "\n",
    "def get_embedding_distractors(correct_answer: str, context: str, top_k=5) -> List[str]:\n",
    "    \"\"\"Find better distractors using sentence embeddings and word filtering.\"\"\"\n",
    "    words = list(set(context.lower().split()))\n",
    "    words = [w.strip(\".,()[]\") for w in words if len(w) > 3 and w.lower() != correct_answer.lower()]\n",
    "    words = [w for w in words if w.isalpha()]  # Remove punctuation, numbers, etc.\n",
    "\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        correct_embedding = embedding_model.encode(correct_answer, convert_to_tensor=True)\n",
    "        candidate_embeddings = embedding_model.encode(words, convert_to_tensor=True)\n",
    "        similarities = util.pytorch_cos_sim(correct_embedding, candidate_embeddings)[0]\n",
    "        sorted_indices = similarities.argsort(descending=True)  # Get most similar\n",
    "        distractors = []\n",
    "        for idx in sorted_indices:\n",
    "            candidate = words[idx]\n",
    "            if candidate.lower() != correct_answer.lower() and candidate not in distractors:\n",
    "                distractors.append(candidate)\n",
    "            if len(distractors) == top_k:\n",
    "                break\n",
    "        return distractors\n",
    "    except Exception as e:\n",
    "        print(f\"Distractor generation error: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a14771",
   "metadata": {},
   "source": [
    "### üßπ Question Cleaning and Abbreviation Handling\n",
    "\n",
    "This section refines the generated questions to ensure they are **clean**, **contextually correct**, and **free of leakage** (i.e., directly including the answer in the question).\n",
    "\n",
    "---\n",
    "\n",
    "#### `clean_question(question, answer)`\n",
    "- Ensures that the correct answer is **not explicitly present** in the question.\n",
    "- If found, it replaces the answer with a blank (`\"_____\"`).\n",
    "- Useful to prevent question-answer leakage in MCQs.\n",
    "\n",
    "---\n",
    "\n",
    "#### `replace_abbreviation_in_question(question, answer, abbreviation_candidates)`\n",
    "- Detects and replaces abbreviations or acronyms in the question with the **full answer form**.\n",
    "- Uses regex for **whole word replacement** to prevent partial matches.\n",
    "- Helps improve clarity when abbreviations are present in questions.\n",
    "\n",
    "---\n",
    "\n",
    "#### `find_abbreviations(sentence, answer)`\n",
    "- Heuristically detects abbreviations **following the full form** in parentheses.\n",
    "  - Example: `\"Random Access Memory (RAM)\" ‚Üí ['RAM']`\n",
    "- Filters for **uppercase or short acronyms** (‚â§ 6 characters).\n",
    "- Returns a list of valid abbreviation candidates to be replaced.\n",
    "\n",
    "---\n",
    "\n",
    "> ‚ú® This cleaning and replacement step ensures that generated questions are educationally effective and do not confuse learners by revealing answers prematurely or using unclear acronyms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcc8f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_question(question: str, answer: str) -> str:\n",
    "    \"\"\"Ensure the answer is not directly embedded in the question.\"\"\"\n",
    "    q_lower = question.lower()\n",
    "    a_lower = answer.lower()\n",
    "    if a_lower in q_lower:\n",
    "        return question.replace(answer, \"_____\").strip()\n",
    "    return question.strip()\n",
    "\n",
    "\n",
    "def replace_abbreviation_in_question(question: str, answer: str, abbreviation_candidates: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Replace any detected abbreviation or acronym in the question with the full answer.\n",
    "\n",
    "    abbreviation_candidates: list of abbreviations/acronyms extracted from the sentence that relate to the answer.\n",
    "    \"\"\"\n",
    "    # To avoid partial replacement, do whole word match with regex\n",
    "    for abbr in abbreviation_candidates:\n",
    "        pattern = re.compile(r'\\b' + re.escape(abbr) + r'\\b', flags=re.IGNORECASE)\n",
    "        if pattern.search(question):\n",
    "            question = pattern.sub(answer, question)\n",
    "    return question\n",
    "\n",
    "\n",
    "def find_abbreviations(sentence: str, answer: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Heuristic: find abbreviations in sentence inside parentheses next to answer.\n",
    "\n",
    "    Example: \"Network Interface Card (NIC)\" ‚Üí extract \"NIC\"\n",
    "    \"\"\"\n",
    "    pattern = re.compile(rf\"{re.escape(answer)}\\s*\\(([^)]+)\\)\", flags=re.IGNORECASE)\n",
    "    match = pattern.search(sentence)\n",
    "    if match:\n",
    "        # Return all uppercase abbreviations or short acronyms split by comma/semicolon if any\n",
    "        abbrs = [abbr.strip() for abbr in re.split(r'[;,]', match.group(1))]\n",
    "        # Filter to plausible abbreviations (usually uppercase or short)\n",
    "        return [a for a in abbrs if len(a) <= 6 and a.isupper()]\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708d551d",
   "metadata": {},
   "source": [
    "### üéØ MCQ Generation: `generate()`\n",
    "\n",
    "This function creates high-quality **multiple-choice questions (MCQs)** from structured and filtered educational content.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîß Function: `generate(input_path, output_path, mcq_target)`\n",
    "- **Inputs:**\n",
    "  - `input_path`: Path to processed sentence-level JSON (default: `\"processed_stage2.json\"`).\n",
    "  - `output_path`: Filepath to save generated MCQs.\n",
    "  - `mcq_target`: Number of MCQs to generate (default: 7).\n",
    "\n",
    "---\n",
    "\n",
    "#### üöÄ Steps:\n",
    "1. **Load Cleaned Sentences** from stage 2 output.\n",
    "2. For each sentence:\n",
    "   - Extract first answer candidate.\n",
    "   - Generate question using `<hl>`-based T5 pipeline.\n",
    "   - Replace abbreviations (e.g., ‚ÄúNIC‚Äù) with full answer.\n",
    "   - Clean question to avoid leakage.\n",
    "   - Generate **distractors**:\n",
    "     - Prefer sentence embedding-based similarity.\n",
    "     - Fall back to **WordNet** synonyms.\n",
    "   - Shuffle options and format as MCQ.\n",
    "\n",
    "3. **Save** results in JSON format with:\n",
    "   - `question`, `options`, `answer`, `header`, `source_sentence`.\n",
    "\n",
    "---\n",
    "\n",
    "> ‚ö†Ô∏è Automatically skips low-quality entries (e.g., short questions, poor distractors, or leakage).\n",
    "> Output: `\"improved_mcqs.json\"` (or custom path).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c772706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(input_path=\"processed_stage2.json\", output_path=\"final_mcqs.json\", mcq_target=7):\n",
    "    \"\"\"Generate multiple-choice questions from processed data.\"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_path}\")\n",
    "    \n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    output_mcqs = []\n",
    "    skipped_entries = 0\n",
    "\n",
    "    for entry in data:\n",
    "        if len(output_mcqs) >= mcq_target:\n",
    "            break\n",
    "\n",
    "        sentence = entry.get(\"clean_sentence\", \"\").strip()\n",
    "        answer = entry.get(\"answer_candidates\", [])[0] if entry.get(\"answer_candidates\") else \"\"\n",
    "\n",
    "        if not sentence or not answer:\n",
    "            skipped_entries += 1\n",
    "            continue\n",
    "\n",
    "        question = generate_question_qg(sentence, answer)\n",
    "        if not question:\n",
    "            skipped_entries += 1\n",
    "            continue\n",
    "\n",
    "        # Detect abbreviations related to answer\n",
    "        abbreviations = find_abbreviations(sentence, answer)\n",
    "\n",
    "        # Replace abbreviation in question with full answer\n",
    "        if abbreviations:\n",
    "            question = replace_abbreviation_in_question(question, answer, abbreviations)\n",
    "\n",
    "        question = clean_question(question, answer)\n",
    "\n",
    "        if len(question.split()) < 3 or answer.lower() in question.lower():\n",
    "            skipped_entries += 1\n",
    "            continue\n",
    "\n",
    "        # Generate distractors\n",
    "        distractors = get_embedding_distractors(answer, sentence)\n",
    "        if len(distractors) < 3:\n",
    "            distractors += get_wordnet_distractors(answer)\n",
    "        distractors = list(set(distractors))[:3]\n",
    "\n",
    "        if len(distractors) < 3:\n",
    "            skipped_entries += 1\n",
    "            continue\n",
    "\n",
    "        # Shuffle options\n",
    "        options = distractors + [answer]\n",
    "        random.shuffle(options)\n",
    "\n",
    "        output_mcqs.append({\n",
    "            \"header\": entry.get(\"header\", \"General\"),\n",
    "            \"question\": question,\n",
    "            \"options\": options,\n",
    "            \"answer\": answer,\n",
    "            \"source_sentence\": sentence\n",
    "        })\n",
    "\n",
    "    # Save output\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_mcqs, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"‚úÖ MCQ generation complete. Generated {len(output_mcqs)} MCQs, skipped {skipped_entries} entries due to quality/filtering.\")\n",
    "    print(f\"Output saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b0137",
   "metadata": {},
   "source": [
    "# The main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfb14dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ex1.pdf\n",
      "‚úÖ Found 9 sections.\n",
      "Structured JSON saved to 'structured_output.json'\n",
      "\n",
      "--- Sample output (first 3 sections) ---\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"header\": \"Software Engineering Section 1\",\n",
      "    \"content\": \"Difference between Software and Computer programs Software engineering is intended to support professional software development, rather than individual programming. It includes techniques that support program specification, design, and evolution, none of which are normally relevant for personal software development. Many people think that software is simply another word for computer programs. However, when we are talking about software engineering, software is not just the programs themselves but also all associated documentation and configuration data that is required to make these programs operate correctly. A professionally developed software system is often more than a single program. The system usually consists of a number of separate programs and configuration files that are used to set up these programs. It may include system documentation, which describes the structure of the system; user documentation, which explains how to use the system, and websites for users to download recent product information. This is one of the important differences between professional and amateur software development. If you are writing a program for yourself, no one else will use it and you don‚Äôt have to worry about writing program guides, documenting the program design, etc. However, if you are writing software that other people will use and other engineers will change then you usually have to provide additional information as well as the code of the program. Many applications need software engineering; they do not all need the same software engineering techniques. There are still many reports of software projects going wrong and ‚Äòsoftware failures‚Äô. Software engineering is criticized as inadequate for modern software development. However, in my view, many of these so-called software failures are a\"\n",
      "  },\n",
      "  {\n",
      "    \"header\": \"consequence of two factors\",\n",
      "    \"content\": \"‚Äã Increasing demands ‚Äã Low expectations 1 When we talk about the quality of professional software, we have to take into account that the software is used and changed by people apart from its developers. Quality is therefore not just concerned with what the software does. Rather, it has to include the software‚Äôs behavior while it is executing. This is reflected in so-called quality or non-functional software attributes. Examples of these attributes are the software‚Äôs response time to a user query and the understandability of the program code. The specific set of attributes that you might expect from a software system obviously depends on its application. Therefore, a banking system must be secure, an interactive game must be responsive, a telephone switching system must be reliable, and so on. Essential attributes of a good software Maintainability Software should be written in such a way so that it can evolve to meet the changing needs of customers. This is a critical attribute because software change is an inevitable requirement of a changing business environment. Dependability and security Software dependability includes a range of characteristics including reliability, security, and safety. Dependable software should not cause physical or economic damage in the event of system failure. Malicious users should not be able to access or damage the system. Efficiency Software should not make wasteful use of system resources such as memory and processor cycles. Efficiency therefore includes responsiveness, processing time, memory utilization, etc. Acceptability Software must be acceptable to the type of users for which it is designed. This means that it must be understandable, usable, and compatible with other systems that they use. 2\"\n",
      "  },\n",
      "  {\n",
      "    \"header\": \"SFW Engineering\",\n",
      "    \"content\": \"Software engineering is an engineering discipline that is concerned with all aspects of software production from the early stages of system specification through to maintaining the system after it has gone into use.\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 76 sentences, filtered to 21 by relevance >= 0.5\n",
      "Output saved to 'processed_stage2.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MCQ generation complete. Generated 7 MCQs, skipped 11 entries due to quality/filtering.\n",
      "Output saved to: final_mcqs.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    preprcess(\"ex1.pdf\")  # Change to your file path\n",
    "    extractions()\n",
    "    generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
